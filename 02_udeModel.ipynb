{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "82b612cd",
      "metadata": {
        "id": "82b612cd"
      },
      "source": [
        "# Universal differential equations\n",
        "\n",
        "Esse notebook é uma demonstração de 'Universal differential equations' (UDE) usando modelos de circuitos equivalentes e PyBaMM. Uma UDE é uma equação diferencial definito, por todo ou em parte, em função de \"aproximadores universais\" (redes-neurais nesse caso).\n",
        "\n",
        "Na prática, são sistema físicos, descritos por equações diferenciais, onde um dos componentes é uma rede neural[1]. Exemplo: $$\\frac{\\partial u}{\\partial t} = f(x,u,t) + \\mathcal{NN}(x,u)$$\n",
        "\n",
        "Vantagem dessa implementação: $f(\\cdot)$ pode ser um modelo físico simplificado (*reduced order*) que retorna uma mera aproximação do resultado real. Nesse caso, a rede neural $\\mathcal{NN}$ pode ser menor, mais simples, responsável somente por corrigir o erro, a divergência.\n",
        "\n",
        "---\n",
        "- Rackauckas et al 2021 (https://doi.org/10.48550/arXiv.2001.04385)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5a51691",
      "metadata": {
        "id": "f5a51691"
      },
      "source": [
        "## Exemplo Neural-TECMD\n",
        "O melhor exemplo, com código open-source disponível online, vem de Kuzhiyil et al, 2024 [2, 3]. O software é implementado em Julia, consegui faze-lo rodar localmente, mas não no Google Colab. Vou demonstrar abaixo a lógica básica do programa e o output do código -- não será possível executar localmente agora.\n",
        "\n",
        "O artigo descreve o processo de combinar modelo  *Thermal Equivalent Circuit Model with Diffusion* (TECMD) -- um dos modelos do tipo ECM mais sofisticados -- com duas redes neurais que corrigem o erro de temperatura e tensão. Na figura abaixo, blocos pretos representam modelos físicos-matemáticos, blocos laranjas representam redes neurais.\n",
        "\n",
        "![test](https://github.com/SarvTex/june_sciml_workshop/blob/main/imgs/neural_tecmd_kuzhiyil.jpg?raw=1)\n",
        "\n",
        "O modelo conseguiu obter reduções de erro significativo, enquanto preserva performance.\n",
        "\n",
        "A figura abaixo demonstra a comparação entre dados experimentais, e os resultados da simulação com e sem redes-neurais auxiliares.\n",
        "\n",
        "![test](https://github.com/SarvTex/june_sciml_workshop/blob/main/imgs/neural_tecmd_plot.png?raw=1){width:300px}\n",
        "\n",
        "---\n",
        "- Kuzhiyil et al 2024 (https://doi.org/10.1016/j.apenergy.2024.123692)\n",
        "- https://github.com/JishnuKuzhiyil/Neural-TECMD-Battery-model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc42b792",
      "metadata": {
        "id": "cc42b792"
      },
      "source": [
        "## Inicialização Colab\n",
        "Caso esse notebook esteja sendo executado pelo Google Colab, algumas modificações tem que ser feitas. O bloco abaixo reorganiza esses aspectos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e487c35e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e487c35e",
        "outputId": "0f702dd4-692f-4b49-943a-cd141b2fabd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Code running in Colab env ===\n",
            "> Cloning repo (dataset) ===\n",
            "Cloning into 'june_sciml_workshop'...\n",
            "remote: Enumerating objects: 448, done.\u001b[K\n",
            "remote: Counting objects: 100% (448/448), done.\u001b[K\n",
            "remote: Compressing objects: 100% (434/434), done.\u001b[K\n",
            "remote: Total 448 (delta 18), reused 439 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (448/448), 37.76 MiB | 10.29 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "Updating files: 100% (398/398), done.\n",
            "> Currently in correct folder (/content/june_sciml_workshop) ===\n",
            "01_pinnModel.ipynb\t\t   data\t\t       imgs\n",
            "02_udeModel.ipynb\t\t   enviroment.yml      README.md\n",
            "03_physicsFeature_synthData.ipynb  explore_data.ipynb  test.ipynb\n"
          ]
        }
      ],
      "source": [
        "# importing basic libs\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# setting up code to run in google colab\n",
        "git_repo_url = \"https://github.com/SarvTex/june_sciml_workshop.git\"\n",
        "repo_name = \"june_sciml_workshop\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # Google colab setup\n",
        "    print(\"> Code running in Colab env ===\")\n",
        "\n",
        "    if not repo_name in os.getcwd().split(os.sep) and not repo_name in os.listdir():\n",
        "        print(\"> Cloning repo (dataset) ===\")\n",
        "        !git clone {git_repo_url}\n",
        "    else:\n",
        "      print(\"> Repo already cloned ===\")\n",
        "\n",
        "    if repo_name in os.listdir():\n",
        "        os.chdir(repo_name)\n",
        "    print(f\"> Currently in correct folder ({os.getcwd()}) ===\")\n",
        "\n",
        "else:\n",
        "    # Running locally setup\n",
        "    print(\"> Running locally. Assuming correct folder structure ===\")\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31292c60",
      "metadata": {},
      "source": [
        "## RNN para ODE\n",
        "Abaixo uma representação básica de uma RNN sendo usada para resolver um problema de equações diferenciais.  \n",
        "Esse exemplo vem de Nascimento et al (2020), código disponível em Github. Esse artigo usa formação de rupturas mecânicas baseado na [Lei de Paris Erdogan](https://en.wikipedia.org/wiki/Paris'_law).\n",
        "\n",
        "Aqui, a rede neural RNN opera como uma '*integradora*', ou seja, computa a derivada no tempo de $y_n$ e determina um novo valor para $y_{n+1}$. Nesse exemplo em específico, a integração é baseado no alg de Euler, uma das metodologias de integrações mais simples.\n",
        "\n",
        "![img](imgs/typesOfCell_nascimentoRNN.jpg)\n",
        "\n",
        "---\n",
        "- \"[Nascimento, R. G., Fricke, K., & Viana, F. A. C. (2020)](https://www.sciencedirect.com/science/article/pii/S095219762030292X). A tutorial on solving ordinary differential equations using Python and hybrid physics-informed neural networks. Engineering Applications of Artificial Intelligence, 96, 103996.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a140b621",
      "metadata": {
        "id": "a140b621"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
            "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "#from tensorflow.keras.layers import RNN, Dense, Layer\n",
        "#from tensorflow.keras import Sequential\n",
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "#from tensorflow.python.framework import tensor_shape\n",
        "#from tensorflow import float32, concat, convert_to_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91d794ce",
      "metadata": {},
      "source": [
        "No tensorflow, pode-se criar \"*layers*\" customizadas. Para usá-las em um RNN, programa-se esse layer como uma \"*cell*\". obrigatório definir as funções `__init__` e `call` dessa classe. Exemplo de pseudo-código abaixo.\n",
        "```python\n",
        "# pseudo-code ----\n",
        "class CustomCell(tf.keras.layers.Layer):\n",
        "    def __init__(self, x): # ...\n",
        "    def call(self, x): # ...\n",
        "\n",
        "rnn_cell = CustomCell(x)\n",
        "rnn = tf.keras.layers.RNN(cell=rnn_cell, ...)\n",
        "# ---\n",
        "```\n",
        "\n",
        "Dentro da `EulerIntergratorCell`, existe uma rede neural `dKlayer`, que calcula o termo $\\Delta K$ da equação de Paris."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c260b74a",
      "metadata": {},
      "outputs": [],
      "source": [
        "class EulerIntegratorCell(tf.keras.layers.Layer):\n",
        "    def __init__(self, C, m, dKlayer, a0=None, units=1, **kwargs):\n",
        "        super(EulerIntegratorCell, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.C     = C\n",
        "        self.m     = m\n",
        "        self.a0    = a0\n",
        "        self.dKlayer     = dKlayer\n",
        "        self.state_size  = tf.TensorShape(self.units)\n",
        "        self.output_size = tf.TensorShape(self.units)\n",
        "\n",
        "    def build(self, input_shape, **kwargs):\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        inputs  = tf.convert_to_tensor(inputs)\n",
        "        a_tm1   = tf.convert_to_tensor(states)\n",
        "        x_d_tm1 = tf.concat((inputs, a_tm1[0, :]), axis=1)\n",
        "        dk_t    = self.dKlayer(x_d_tm1)\n",
        "        da_t    = self.C * (dk_t ** self.m)\n",
        "        a       = da_t + a_tm1[0, :]\n",
        "        return a, [a]\n",
        "\n",
        "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
        "        return self.a0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "051dfc6e",
      "metadata": {},
      "source": [
        "Outro uso para a função \"layer customizada\": Camada de 'normalização'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a5d66b",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Normalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, S_low, S_up, a_low, a_up, **kwargs):\n",
        "        super(Normalization, self).__init__(**kwargs)\n",
        "        self.low_bound_S   = S_low\n",
        "        self.upper_bound_S = S_up\n",
        "        self.low_bound_a   = a_low\n",
        "        self.upper_bound_a = a_up\n",
        "\n",
        "    def build(self, input_shape, **kwargs):\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output  = (inputs - [self.low_bound_S, self.low_bound_a]) / [(self.upper_bound_S - self.low_bound_S), (self.upper_bound_a - self.low_bound_a)]\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "301b13c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def create_model(C, m, a0, dKlayer, batch_input_shape, return_sequences=False, return_state=False):\n",
        "    euler = EulerIntegratorCell(C=C, m=m, dKlayer=dKlayer, a0=a0, batch_input_shape=batch_input_shape)\n",
        "    PINN  = tf.keras.layers.RNN(cell=euler, batch_input_shape=batch_input_shape, return_sequences=return_sequences, return_state=return_state)\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(PINN)\n",
        "    model.compile(loss='mse', optimizer=tf.keras.optimizers.RMSprop(1e-2))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63392f15",
      "metadata": {},
      "source": [
        "Dentro da 'Euler cell', existe uma rede neural que preve $\\Delta K$ chamada `dKlayer`. Esse rede é pré-iniciada aqui, antes mesmo de se criar o RNN. Nota-se que esse NN é inicialmente treinada de acordo com a fórmula `dK_range`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa6cc81",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paris law coefficients\n",
        "[C, m] = [1.5E-11, 3.8]\n",
        "\n",
        "# data\n",
        "Strain = np.asarray(pd.read_csv('./data/ude_nascimento/Strain.csv'))[:,:,np.newaxis]\n",
        "atrain = np.asarray(pd.read_csv('./data/ude_nascimento/atrain.csv'))\n",
        "a0     = np.asarray(pd.read_csv('./data/ude_nascimento/a0.csv'))[0,0]*np.ones((Strain.shape[0],1))\n",
        "\n",
        "# stress-intensity layer\n",
        "dKlayer = tf.keras.Sequential()\n",
        "dKlayer.add(Normalization(np.min(Strain), np.max(Strain), np.min(atrain), np.max(atrain)))\n",
        "dKlayer.add(tf.keras.layers.Dense(5, activation='tanh'))\n",
        "dKlayer.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# weight initialization\n",
        "S_range  = np.linspace(np.min(Strain), np.max(Strain), 1000)\n",
        "a_range  = np.linspace(np.min(atrain), np.max(atrain), 1000)[np.random.permutation(np.arange(1000))]\n",
        "dK_range = -12.05 + 0.24 * S_range + 760.0 * a_range\n",
        "\n",
        "dKlayer.compile(loss='mse', optimizer=tf.keras.optimizer.RMSprop(1e-2))\n",
        "inputs_train = np.transpose(np.asarray([S_range, a_range]))\n",
        "dKlayer.fit(inputs_train, dK_range, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c552500",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# fitting physics-informed neural network\n",
        "model = create_model(C=C, m=m, a0=tf.convert_to_tensor(a0, dtype=tf.float32), dKlayer=dKlayer, batch_input_shape=Strain.shape)\n",
        "aPred_before = model.predict_on_batch(Strain)[:,:]\n",
        "model.fit(Strain, atrain, epochs=100, steps_per_epoch=1, verbose=1)\n",
        "aPred = model.predict_on_batch(Strain)[:,:]\n",
        "\n",
        "# plotting predictions\n",
        "fig = plt.figure()\n",
        "plt.plot([0,0.05],[0,0.05],'--k')\n",
        "plt.plot(atrain, aPred_before, 'o', label = 'before training')\n",
        "plt.plot(atrain, aPred, 's', label = 'after training')\n",
        "plt.xlabel(\"actual crack length (m)\")\n",
        "plt.ylabel(\"predicted crack length (m)\")\n",
        "plt.legend(loc = 'upper center',facecolor = 'w')\n",
        "plt.grid(which='both')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0e0a676",
      "metadata": {},
      "source": [
        "## Modelo próprio\n",
        "Abaixo um modelo próprio baseado no que foi apresentado acima.  \n",
        "Essa rede-neural (RNN) representa um ECM básico que é composto de uma fonte de tensão e uma resitência R0.\n",
        "\n",
        "O modelo simplificado da rede de tensão segue a simplificação: $ V(x) = U_0 + \\beta\\cdot\\log(\\frac{x}{1-x}) $.\n",
        "\n",
        "Acho que essa tentativa tem potencial, ainda vou continuar trabalhando nisso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "oTTIiPFYwjE8",
      "metadata": {
        "id": "oTTIiPFYwjE8"
      },
      "outputs": [],
      "source": [
        "class SimpleEquivalentCircuitModel(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    These are the model inputs:\n",
        "        U_max | Max voltage\n",
        "        U_min | Min voltage\n",
        "        Ro | Internal resistance Ro\n",
        "        ecm_nn | The neural net for correcting the physical model (pre-trained)\n",
        "        soc_0 = 0.95, | Initial state of charge\n",
        "        time_step = 10, | Time step\n",
        "        units = 3, | Number of outputs/inner states\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 U_max:np.float32,\n",
        "                 U_min:np.float32,\n",
        "                 Ro:np.float32,\n",
        "                 capacity:np.float32,\n",
        "                 ecm_nn,\n",
        "                 soc_0 = 0.95,\n",
        "                 time_step = 10,\n",
        "                 units = 2,\n",
        "                 **kwargs):\n",
        "        super(SimpleEquivalentCircuitModel, self).__init__(**kwargs)\n",
        "        self.U0 = 0.5 * (U_max + U_min)\n",
        "        self.dU = 0.5 * (U_max - U_min) * 0.2175\n",
        "        self.Ro = Ro\n",
        "        self.capacity = capacity\n",
        "        self.soc_0 = soc_0\n",
        "        self.dt = time_step\n",
        "        self.ecm_nnet = ecm_nn\n",
        "        # units\n",
        "        self.state_size = tf.TensorShape(units)\n",
        "        self.output_size = tf.TensorShape(units)\n",
        "\n",
        "    def build(self, input_shape, **kwargs):\n",
        "        self.built = True\n",
        "\n",
        "    def v_out_phys(self, x_t):\n",
        "        # x_t: inputs & state concat\n",
        "        # x_t features: (curr, temp, v_out, soc)\n",
        "        return self.U0 + self.dU * tf.math.log(x_t[:,3]/(1-x_t[:,3])) - self.Ro * x_t[:,0]\n",
        "\n",
        "    def soc_phys(self, x_t):\n",
        "        # coulomb counting:\n",
        "        # dSoc/dt = -I/3600/C\n",
        "        # x_t features: (curr, temp, v_out, soc)\n",
        "        return x_t[:,3] - x_t[:,0] * self.dt / (3600 * self.capacity)\n",
        "\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        # input_t and output_{t-1}\n",
        "        inputs = tf.convert_to_tensor(inputs) # should be a (x,2) tensor: [0] = current, [1] = temperature\n",
        "        out_m1 = tf.convert_to_tensor(states) # should be a (x,2) tensor: [0] = v_out, [1] = soc\n",
        "        x_t = tf.concat((inputs, out_m1[0,:]), axis=1)\n",
        "\n",
        "        out = tf.stack([\n",
        "            self.v_ocv_phys(x_t),\n",
        "            self.soc_phys(x_t)\n",
        "        ])\n",
        "        out = out - self.ecm_nnet(x_t)\n",
        "        return out, [out]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hAUrASMp4d1l",
      "metadata": {
        "id": "hAUrASMp4d1l"
      },
      "source": [
        "#### Explain\n",
        "\n",
        "```python\n",
        "    def call(self, inputs, states):\n",
        "        # input_t and output_{t-1}\n",
        "        inputs = tf.convert_to_tensor(inputs) # should be a (x,2) tensor: [0] = current, [1] = temperature\n",
        "        out_m1 = tf.convert_to_tensor(states) # should be a (x,3) tensor: [0] = v_out, [1] = soc, [2] = v_rc\n",
        "        x_t = tf.concat((inputs, out_m1[0,:]), axis=1)\n",
        "```\n",
        "Note: input should be a (x,2) tensor and states should be a list\n",
        "which gets converted to a (1,x,3) tensor by the convert_to_tensor\n",
        "method, hence this line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a232637",
      "metadata": {},
      "source": [
        "### Usando PyBaMM\n",
        "\n",
        "Python Battery Mathematical Modelling (PyBaMM) é um pacote de Python open-source para simulação eletroquímica de baterias -- tipicamente a classe de modelos mais sofisticada e completa. Essa é uma ferramenta potencialmente muito útil dado nosso interesse em avaliação e diagnóstico de baterias por meio de modelos de simulação.\n",
        "\n",
        "Durante essa demonstração inicial, vamos comparar um modelo ECM básico com o modelo eletroquímico DFN do PyBaMM."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pybamm_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
